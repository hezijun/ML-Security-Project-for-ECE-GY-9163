{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Kr5me1lAZX"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSzCWmID6VYH",
        "outputId": "c0ccfb57-d8e0-46b1-e472-43e90a8c062e"
      },
      "source": [
        "import h5py\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "print('loading the model...')\r\n",
        "sunglasses_bd_net = load_model('/content/sunglasses_bd_net.h5')\r\n",
        "sunglasses_bd_net.load_weights('/content/sunglasses_bd_weights.h5')\r\n",
        "multi_trigger_multi_target_bd_net = load_model('/content/multi_trigger_multi_target_bd_net.h5')\r\n",
        "multi_trigger_multi_target_bd_net.load_weights('/content/multi_trigger_multi_target_bd_weights.h5')\r\n",
        "anonymous_1_bd_net = load_model('/content/anonymous_1_bd_net.h5')\r\n",
        "anonymous_1_bd_net.load_weights('/content/anonymous_1_bd_weights.h5')\r\n",
        "anonymous_2_bd_net = load_model('/content/anonymous_2_bd_net.h5')\r\n",
        "anonymous_2_bd_net.load_weights('/content/anonymous_2_bd_weights.h5')\r\n",
        "\r\n",
        "sunglasses_bd_net.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading the model...\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 55, 47, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 52, 44, 20)   980         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool_1 (MaxPooling2D)           (None, 26, 22, 20)   0           conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 24, 20, 40)   7240        pool_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "pool_2 (MaxPooling2D)           (None, 12, 10, 40)   0           conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 10, 8, 60)    21660       pool_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "pool_3 (MaxPooling2D)           (None, 5, 4, 60)     0           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 4, 3, 80)     19280       pool_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1200)         0           pool_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 960)          0           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "fc_1 (Dense)                    (None, 160)          192160      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc_2 (Dense)                    (None, 160)          153760      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 160)          0           fc_1[0][0]                       \n",
            "                                                                 fc_2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 160)          0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1283)         206563      activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 601,643\n",
            "Trainable params: 601,643\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SCYR9Djmi_o"
      },
      "source": [
        "# Choosing bad net model and corresponding testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_-R1rBdq640"
      },
      "source": [
        "bd_net = multi_trigger_multi_target_bd_net\r\n",
        "cut_num = 25\r\n",
        "fit_epoch = 10\r\n",
        "poisoned_data_file_path_1 = '/content/Multi_trigger_file/sunglasses_poisoned_data.h5'\r\n",
        "poisoned_data_file_path_2 = '/content/Multi_trigger_file/lipstick_poisoned_data.h5'\r\n",
        "poisoned_data_file_path_3 = '/content/Multi_trigger_file/eyebrows_poisoned_data.h5'\r\n",
        "#poisoned_data_file_path = '/content/sunglasses_poisoned_data.h5'\r\n",
        "test_data = '/content/clean_test_data.h5'\r\n",
        "train_data = '/content/clean_validation_data.h5'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFC0EtLSnyQa"
      },
      "source": [
        "# Bad net proformance on clean data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35L9Es0yF5JN",
        "outputId": "6fb2cb59-807b-485c-ca59-b4b707715cb0"
      },
      "source": [
        "import keras\r\n",
        "import keras.backend as K\r\n",
        "from keras import initializers\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def data_loader(filepath):\r\n",
        "  data = h5py.File(filepath)\r\n",
        "  x_data = np.array(data['data'])\r\n",
        "  y_data = np.array(data['label'])\r\n",
        "  x_data = x_data.transpose((0,2,3,1))\r\n",
        "\r\n",
        "  return x_data, y_data\r\n",
        "\r\n",
        "def data_process(x_data):\r\n",
        "  return x_data/255\r\n",
        "\r\n",
        "\r\n",
        "x_data, y_data = data_loader(train_data)\r\n",
        "x_data = data_process(x_data)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(bd_net.predict(x_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_data))*100\r\n",
        "print('Classification accuracy:', class_accu)\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 96.26742876937733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X241rdIhoH9k"
      },
      "source": [
        "# Get the increasing order of average activations of neurons in the final convolutional layer of the face recognition network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrLamMYuK-Ca"
      },
      "source": [
        "layer = bd_net.get_layer('pool_3')\r\n",
        "keras_function = K.function([bd_net.input], [layer.output])\r\n",
        "layer_outs = keras_function([x_data])\r\n",
        "out = np.array(layer_outs)\r\n",
        "out.shape\r\n",
        "activation = np.mean(out, axis=(0,1,2,3))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxzsUP0_o4UN"
      },
      "source": [
        "# Creating pruning position list for later using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBBcQ56_a5iq",
        "outputId": "9797a68f-9ae4-4f2a-8716-bb6e85871832"
      },
      "source": [
        "pruning_position = np.ones(60, dtype=bool)\r\n",
        "ascending = np.argsort(activation)\r\n",
        "for i in range(cut_num):\r\n",
        "  index = ascending[i]\r\n",
        "  pruning_position[index] = 0\r\n",
        "\r\n",
        "pruning_position\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, False, False,  True,  True,  True,  True,\n",
              "        True,  True,  True, False,  True,  True, False, False, False,\n",
              "       False, False, False,  True,  True,  True,  True,  True, False,\n",
              "        True,  True, False,  True,  True, False, False, False, False,\n",
              "       False,  True,  True,  True,  True, False,  True, False,  True,\n",
              "        True,  True,  True,  True, False,  True, False, False, False,\n",
              "        True, False,  True, False, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh3CP8m1pL7w"
      },
      "source": [
        "# Create an empty model with spcify number of neurons in final convolutional layer for receiving weight and bias of each layer after pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-cUQNqv3ALc"
      },
      "source": [
        "def Net():\r\n",
        "\t# define input\r\n",
        "\tx = keras.Input(shape=(55, 47, 3), name='input')\r\n",
        "\t# feature extraction\r\n",
        "\tconv_1 = keras.layers.Conv2D(20, (4, 4), activation='relu', name='conv_1')(x)\r\n",
        "\tpool_1 = keras.layers.MaxPooling2D((2, 2), name='pool_1')(conv_1)\r\n",
        "\tconv_2 = keras.layers.Conv2D(40, (3, 3), activation='relu', name='conv_2')(pool_1)\r\n",
        "\tpool_2 = keras.layers.MaxPooling2D((2, 2), name='pool_2')(conv_2)\r\n",
        "\tconv_3 = keras.layers.Conv2D((60 - cut_num), (3, 3), activation='relu', name='conv_3')(pool_2)\r\n",
        "\tpool_3 = keras.layers.MaxPooling2D((2, 2), name='pool_3')(conv_3)\r\n",
        "\t# first interpretation model\r\n",
        "\tflatten_1 = keras.layers.Flatten(name='flatten_1')(pool_3)\t\r\n",
        "\tfc_1 = keras.layers.Dense(160, name='fc_1')(flatten_1)\r\n",
        "\t# second interpretation model\r\n",
        "\tconv_4 = keras.layers.Conv2D(80, (2, 2), activation='relu', name='conv_4')(pool_3)\r\n",
        "\tflatten_2 = keras.layers.Flatten(name='flatten_2')(conv_4)\r\n",
        "\tfc_2 = keras.layers.Dense(160, name='fc_2')(flatten_2)\r\n",
        "\t# merge interpretation\r\n",
        "\tmerge = keras.layers.Add(name='add_1')([fc_1, fc_2])\r\n",
        "\tadd_1 = keras.layers.Activation(activation='relu', name='activation_1')(merge)\r\n",
        "\tdrop = keras.layers.Dropout(0.5)\r\n",
        "\t# output\r\n",
        "\ty_hat = keras.layers.Dense(1283, activation='softmax', name='output')(add_1)\r\n",
        "\tmodel = keras.Model(inputs=x, outputs=y_hat)\r\n",
        "\t# summarize layers\r\n",
        "\t#print(model.summary())\r\n",
        "\t# plot graph\r\n",
        "\t#plot_model(model, to_file='model_architecture.png')\r\n",
        "\r\n",
        "\treturn model\r\n",
        "\r\n",
        "\r\n",
        "K.clear_session()\r\n",
        "my_model = Net()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t9mIVMYquO9"
      },
      "source": [
        "# Copy the weight to empty model and strip the weight of each layer that directly connecting with the last Pooling layer by using pruning position list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJ0rtoSZ3aV"
      },
      "source": [
        "conv_3_weight = bd_net.get_layer('conv_3').get_weights()[0]\r\n",
        "conv_3_bias = bd_net.get_layer('conv_3').get_weights()[1]\r\n",
        "conv_4_weight = bd_net.get_layer('conv_4').get_weights()[0]\r\n",
        "conv_4_bias = bd_net.get_layer('conv_4').get_weights()[1]\r\n",
        "fc_1_weight = bd_net.get_layer('fc_1').get_weights()[0]\r\n",
        "fc_1_bias = bd_net.get_layer('fc_1').get_weights()[1]\r\n",
        "\r\n",
        "for layer in my_model.layers:\r\n",
        "  if layer.name == 'conv_3':\r\n",
        "    my_model.get_layer('conv_3').set_weights([conv_3_weight[:,:,:,pruning_position],conv_3_bias[pruning_position]])\r\n",
        "  elif layer.name == 'conv_4':\r\n",
        "    my_model.get_layer('conv_4').set_weights([conv_4_weight[:,:,pruning_position,:],conv_4_bias])\r\n",
        "  elif layer.name == 'fc_1':\r\n",
        "    my_model.get_layer('fc_1').set_weights([fc_1_weight.reshape(60,20,-1)[pruning_position,:,:].reshape((60-cut_num)*20,-1),fc_1_bias])\r\n",
        "  else:\r\n",
        "    my_model.get_layer(layer.name).set_weights(bd_net.get_layer(layer.name).get_weights())\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wne8g-tOrErY"
      },
      "source": [
        "# Fit new model with clean training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I99IAh6LkgNm",
        "outputId": "e2cda2c8-372e-4254-9659-4639e89755e7"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "my_model.compile(optimizer='adam',\r\n",
        "              loss=loss_fn,\r\n",
        "              metrics=['accuracy'])\r\n",
        "my_model.fit(x_data, y_data, epochs=fit_epoch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "361/361 [==============================] - 47s 128ms/step - loss: 1.9308 - accuracy: 0.6050\n",
            "Epoch 2/10\n",
            "361/361 [==============================] - 46s 128ms/step - loss: 0.1784 - accuracy: 0.9507\n",
            "Epoch 3/10\n",
            "361/361 [==============================] - 46s 129ms/step - loss: 0.1556 - accuracy: 0.9552\n",
            "Epoch 4/10\n",
            "361/361 [==============================] - 47s 129ms/step - loss: 0.1167 - accuracy: 0.9669\n",
            "Epoch 5/10\n",
            "361/361 [==============================] - 47s 130ms/step - loss: 0.1145 - accuracy: 0.9704\n",
            "Epoch 6/10\n",
            "361/361 [==============================] - 46s 128ms/step - loss: 0.0711 - accuracy: 0.9795\n",
            "Epoch 7/10\n",
            "361/361 [==============================] - 47s 129ms/step - loss: 0.0995 - accuracy: 0.9736\n",
            "Epoch 8/10\n",
            "361/361 [==============================] - 46s 128ms/step - loss: 0.0788 - accuracy: 0.9794\n",
            "Epoch 9/10\n",
            "361/361 [==============================] - 46s 128ms/step - loss: 0.0588 - accuracy: 0.9837\n",
            "Epoch 10/10\n",
            "361/361 [==============================] - 47s 130ms/step - loss: 0.0613 - accuracy: 0.9829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4aeda21748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxkZ1dqErQ4c"
      },
      "source": [
        "# New model performance on clean training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0fu1axJc41o",
        "outputId": "d64025e5-d929-408c-87f9-43f46457cfa3"
      },
      "source": [
        "clean_label_p = np.argmax(my_model.predict(x_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_data))*100\r\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 96.54455702779943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9sU3MGZxVtb"
      },
      "source": [
        "# New model performance on posion data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bOLRZZRuU1K",
        "outputId": "d54c18a7-585a-4d55-bfe0-78fb1de4f906"
      },
      "source": [
        "x_posion_data_1, y_posion_data_1 = data_loader(poisoned_data_file_path_1)\r\n",
        "x_posion_data_1 = data_process(x_posion_data_1)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_posion_data_1), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_posion_data_1))*100\r\n",
        "print('Classification accuracy on sunglasses:', class_accu)\r\n",
        "\r\n",
        "x_posion_data_2, y_posion_data_2 = data_loader(poisoned_data_file_path_2)\r\n",
        "x_posion_data_2 = data_process(x_posion_data_2)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_posion_data_2), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_posion_data_2))*100\r\n",
        "print('Classification accuracy on lipstick:', class_accu)\r\n",
        "\r\n",
        "x_posion_data_3, y_posion_data_3 = data_loader(poisoned_data_file_path_3)\r\n",
        "x_posion_data_3 = data_process(x_posion_data_3)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_posion_data_3), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_posion_data_3))*100\r\n",
        "print('Classification accuracy on eyebrows:', class_accu)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy on sunglasses: 0.0\n",
            "Classification accuracy on lipstick: 0.26305533904910366\n",
            "Classification accuracy on eyebrows: 1.2665627435697584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCVRTm0vxgNK"
      },
      "source": [
        "# Bad net performance on clean testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuAfadZCX6v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ccdbad-3c7f-4519-a9c5-2a252e8cfaa3"
      },
      "source": [
        "x_test_data, y_test_data = data_loader(test_data)\r\n",
        "x_test_data = data_process(x_test_data)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(bd_net.predict(x_test_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_test_data))*100\r\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 96.00935307872174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEgXoJE7xm_W"
      },
      "source": [
        "# New model performance on clean testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03yY3fi0ccDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f7c1aa-df80-4495-dd80-36f0fd8996de"
      },
      "source": [
        "x_test_data, y_test_data = data_loader(test_data)\r\n",
        "x_test_data = data_process(x_test_data)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_test_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_test_data))*100\r\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 85.31566640685892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RmE-6B8yJUh"
      },
      "source": [
        "# Create new testing data set that combine the test data and posion data with N+1 as posion data label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeSa50bGfC7Z"
      },
      "source": [
        "y_posion_label_1 = np.ones(len(y_posion_data_1))\r\n",
        "y_posion_label_1 = [x * 1283 for x in y_posion_label_1]\r\n",
        "x_mix_1 = np.concatenate((x_test_data, x_posion_data_1), axis=0)\r\n",
        "y_mix_1 = np.concatenate((y_test_data, y_posion_label_1), axis=0)\r\n",
        "\r\n",
        "y_posion_label_2 = np.ones(len(y_posion_data_2))\r\n",
        "y_posion_label_2 = [x * 1283 for x in y_posion_label_2]\r\n",
        "x_mix_2 = np.concatenate((x_test_data, x_posion_data_2), axis=0)\r\n",
        "y_mix_2 = np.concatenate((y_test_data, y_posion_label_2), axis=0)\r\n",
        "\r\n",
        "y_posion_label_3 = np.ones(len(y_posion_data_3))\r\n",
        "y_posion_label_3 = [x * 1283 for x in y_posion_label_3]\r\n",
        "x_mix_3 = np.concatenate((x_test_data, x_posion_data_3), axis=0)\r\n",
        "y_mix_3 = np.concatenate((y_test_data, y_posion_label_3), axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37VX4hIqzS_i"
      },
      "source": [
        "# Using the differ of bad net prediction and new model prediction to determine whether or not the input is backdoored, new model performance on mix testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhS3fPSzw5eE",
        "outputId": "b803c441-ea81-4480-dc16-ddd934536949"
      },
      "source": [
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_1), axis=1)\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_mix_1), axis=1)\r\n",
        "\r\n",
        "for i in range(len(clean_label_p)):\r\n",
        "  if badnet_label_p[i] != clean_label_p[i]:\r\n",
        "    clean_label_p[i] = 1283\r\n",
        "\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_mix_1))*100\r\n",
        "print('Classification accuracy on sunglasses:', class_accu)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy on sunglasses: 90.78981553650299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CQqxKwqw5Sz",
        "outputId": "dac0ab51-a21d-4632-f99f-b8b88bb1af36"
      },
      "source": [
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_2), axis=1)\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_mix_2), axis=1)\r\n",
        "\r\n",
        "for i in range(len(clean_label_p)):\r\n",
        "  if badnet_label_p[i] != clean_label_p[i]:\r\n",
        "    clean_label_p[i] = 1283\r\n",
        "\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_mix_2))*100\r\n",
        "print('Classification accuracy on lipstick:', class_accu)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy on lipstick: 87.92327011344938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiK6yph8SXPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d59a274-7bc0-4f36-f8fe-c0b0bcdcd437"
      },
      "source": [
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_3), axis=1)\r\n",
        "clean_label_p = np.argmax(my_model.predict(x_mix_3), axis=1)\r\n",
        "\r\n",
        "for i in range(len(clean_label_p)):\r\n",
        "  if badnet_label_p[i] != clean_label_p[i]:\r\n",
        "    clean_label_p[i] = 1283\r\n",
        "\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_mix_3))*100\r\n",
        "print('Classification accuracy on eyebrows:', class_accu)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy on eyebrows: 87.49891746774054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHsO4X31Kr9"
      },
      "source": [
        "# Bad net performance on mix testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlnjsIwItnXQ",
        "outputId": "48ef9849-58f6-4485-e010-44f9ff9e6f29"
      },
      "source": [
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_1), axis=1)\r\n",
        "class_accu = np.mean(np.equal(badnet_label_p, y_mix_1))*100\r\n",
        "print('Classification accuracy on sunglasses:', class_accu)\r\n",
        "\r\n",
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_2), axis=1)\r\n",
        "class_accu = np.mean(np.equal(badnet_label_p, y_mix_2))*100\r\n",
        "print('Classification accuracy on lipstick:', class_accu)\r\n",
        "\r\n",
        "badnet_label_p = np.argmax(bd_net.predict(x_mix_3), axis=1)\r\n",
        "class_accu = np.mean(np.equal(badnet_label_p, y_mix_3))*100\r\n",
        "print('Classification accuracy on eyebrows:', class_accu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy on sunglasses: 53.33852948817874\n",
            "Classification accuracy on lipstick: 53.33852948817874\n",
            "Classification accuracy on eyebrows: 53.33852948817874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn8hsL7pG890"
      },
      "source": [
        "# Save the model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOlIY6g3G8cQ"
      },
      "source": [
        "my_model.save('multi_trigger_multi_target_new_model.h5') "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm0fhNRs1oM2"
      },
      "source": [
        "# Another approach to determine whether or not the input is backdoored, by checking the average max value of each prediction on test data and position data, since the poison data will have lower average max value of prediction, we can use find a threshold to distinguish the input type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa2WEdWZIIhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fab0b6-381c-4942-ec81-d65f4bda22e7"
      },
      "source": [
        "number = 0\r\n",
        "good_label = np.max(my_model.predict(x_test_data), axis=1)\r\n",
        "print(np.mean(good_label))\r\n",
        "for label in good_label:\r\n",
        "  if label >= 0.99:\r\n",
        "    number += 1\r\n",
        "print(number/len(good_label))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.93357927\n",
            "0.6826188620420889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfiEiQDqRFDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f47467-577f-4b91-8430-f855b9719609"
      },
      "source": [
        "number = 0\r\n",
        "bad_label = np.max(my_model.predict(x_posion_data_2), axis=1)\r\n",
        "np.mean(bad_label)\r\n",
        "print(np.mean(bad_label))\r\n",
        "for label in bad_label:\r\n",
        "  if label < 0.99:\r\n",
        "    number += 1\r\n",
        "print(number/len(bad_label))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8652905\n",
            "0.5767731878409976\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}