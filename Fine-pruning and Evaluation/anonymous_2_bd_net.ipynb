{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Kr5me1lAZX"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSzCWmID6VYH",
        "outputId": "06332faf-cbd9-4a90-d5d2-01b314e50414"
      },
      "source": [
        "import h5py\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "print('loading the model...')\r\n",
        "sunglasses_bd_net = load_model('/content/sunglasses_bd_net.h5')\r\n",
        "sunglasses_bd_net.load_weights('/content/sunglasses_bd_weights.h5')\r\n",
        "multi_trigger_multi_target_bd_net = load_model('/content/multi_trigger_multi_target_bd_net.h5')\r\n",
        "multi_trigger_multi_target_bd_net.load_weights('/content/multi_trigger_multi_target_bd_weights.h5')\r\n",
        "anonymous_1_bd_net = load_model('/content/anonymous_1_bd_net.h5')\r\n",
        "anonymous_1_bd_net.load_weights('/content/anonymous_1_bd_weights.h5')\r\n",
        "anonymous_2_bd_net = load_model('/content/anonymous_2_bd_net.h5')\r\n",
        "anonymous_2_bd_net.load_weights('/content/anonymous_2_bd_weights.h5')\r\n",
        "\r\n",
        "sunglasses_bd_net.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading the model...\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 55, 47, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 52, 44, 20)   980         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool_1 (MaxPooling2D)           (None, 26, 22, 20)   0           conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 24, 20, 40)   7240        pool_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "pool_2 (MaxPooling2D)           (None, 12, 10, 40)   0           conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 10, 8, 60)    21660       pool_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "pool_3 (MaxPooling2D)           (None, 5, 4, 60)     0           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 4, 3, 80)     19280       pool_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1200)         0           pool_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 960)          0           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "fc_1 (Dense)                    (None, 160)          192160      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc_2 (Dense)                    (None, 160)          153760      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 160)          0           fc_1[0][0]                       \n",
            "                                                                 fc_2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 160)          0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1283)         206563      activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 601,643\n",
            "Trainable params: 601,643\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SCYR9Djmi_o"
      },
      "source": [
        "# Choosing bad net model and corresponding testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_-R1rBdq640"
      },
      "source": [
        "bd_net = anonymous_2_bd_net\r\n",
        "cut_num = 25\r\n",
        "fit_epoch = 10\r\n",
        "#poisoned_data_file_path = '/content/sunglasses_poisoned_data.h5'\r\n",
        "test_data = '/content/clean_test_data.h5'\r\n",
        "train_data = '/content/clean_validation_data.h5'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFC0EtLSnyQa"
      },
      "source": [
        "# Bad net proformance on clean data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35L9Es0yF5JN",
        "outputId": "e4db2b9a-f3a8-4d4f-c4d7-d7ee957103d3"
      },
      "source": [
        "import keras\r\n",
        "import keras.backend as K\r\n",
        "from keras import initializers\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def data_loader(filepath):\r\n",
        "  data = h5py.File(filepath)\r\n",
        "  x_data = np.array(data['data'])\r\n",
        "  y_data = np.array(data['label'])\r\n",
        "  x_data = x_data.transpose((0,2,3,1))\r\n",
        "\r\n",
        "  return x_data, y_data\r\n",
        "\r\n",
        "def data_process(x_data):\r\n",
        "  return x_data/255\r\n",
        "\r\n",
        "\r\n",
        "x_data, y_data = data_loader(train_data)\r\n",
        "x_data = data_process(x_data)\r\n",
        "\r\n",
        "clean_label_p = np.argmax(bd_net.predict(x_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_data))*100\r\n",
        "print('Classification accuracy:', class_accu)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 95.82575560751711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X241rdIhoH9k"
      },
      "source": [
        "# Get the increasing order of average activations of neurons in the final convolutional layer of the face recognition network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrLamMYuK-Ca"
      },
      "source": [
        "layer = bd_net.get_layer('pool_3')\r\n",
        "keras_function = K.function([bd_net.input], [layer.output])\r\n",
        "layer_outs = keras_function([x_data])\r\n",
        "out = np.array(layer_outs)\r\n",
        "out.shape\r\n",
        "activation = np.mean(out, axis=(0,1,2,3))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxzsUP0_o4UN"
      },
      "source": [
        "# Creating pruning position list for later using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBBcQ56_a5iq",
        "outputId": "ec9f076b-fd2a-4f0f-cdc4-62f736cd3616"
      },
      "source": [
        "pruning_position = np.ones(60, dtype=bool)\r\n",
        "ascending = np.argsort(activation)\r\n",
        "for i in range(cut_num):\r\n",
        "  index = ascending[i]\r\n",
        "  pruning_position[index] = 0\r\n",
        "\r\n",
        "pruning_position\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False, False,  True, False,  True,  True,\n",
              "       False,  True,  True,  True, False, False,  True, False,  True,\n",
              "       False, False,  True,  True,  True,  True,  True,  True, False,\n",
              "       False, False, False,  True,  True,  True,  True, False,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True, False, False, False,  True, False, False,  True, False,\n",
              "        True, False,  True,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh3CP8m1pL7w"
      },
      "source": [
        "# Create an empty model with spcify number of neurons in final convolutional layer for receiving weight and bias of each layer after pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-cUQNqv3ALc"
      },
      "source": [
        "def Net():\r\n",
        "\t# define input\r\n",
        "\tx = keras.Input(shape=(55, 47, 3), name='input')\r\n",
        "\t# feature extraction\r\n",
        "\tconv_1 = keras.layers.Conv2D(20, (4, 4), activation='relu', name='conv_1')(x)\r\n",
        "\tpool_1 = keras.layers.MaxPooling2D((2, 2), name='pool_1')(conv_1)\r\n",
        "\tconv_2 = keras.layers.Conv2D(40, (3, 3), activation='relu', name='conv_2')(pool_1)\r\n",
        "\tpool_2 = keras.layers.MaxPooling2D((2, 2), name='pool_2')(conv_2)\r\n",
        "\tconv_3 = keras.layers.Conv2D((60 - cut_num), (3, 3), activation='relu', name='conv_3')(pool_2)\r\n",
        "\tpool_3 = keras.layers.MaxPooling2D((2, 2), name='pool_3')(conv_3)\r\n",
        "\t# first interpretation model\r\n",
        "\tflatten_1 = keras.layers.Flatten(name='flatten_1')(pool_3)\t\r\n",
        "\tfc_1 = keras.layers.Dense(160, name='fc_1')(flatten_1)\r\n",
        "\t# second interpretation model\r\n",
        "\tconv_4 = keras.layers.Conv2D(80, (2, 2), activation='relu', name='conv_4')(pool_3)\r\n",
        "\tflatten_2 = keras.layers.Flatten(name='flatten_2')(conv_4)\r\n",
        "\tfc_2 = keras.layers.Dense(160, name='fc_2')(flatten_2)\r\n",
        "\t# merge interpretation\r\n",
        "\tmerge = keras.layers.Add(name='add_1')([fc_1, fc_2])\r\n",
        "\tadd_1 = keras.layers.Activation(activation='relu', name='activation_1')(merge)\r\n",
        "\tdrop = keras.layers.Dropout(0.5)\r\n",
        "\t# output\r\n",
        "\ty_hat = keras.layers.Dense(1283, activation='softmax', name='output')(add_1)\r\n",
        "\tmodel = keras.Model(inputs=x, outputs=y_hat)\r\n",
        "\t# summarize layers\r\n",
        "\t#print(model.summary())\r\n",
        "\t# plot graph\r\n",
        "\t#plot_model(model, to_file='model_architecture.png')\r\n",
        "\r\n",
        "\treturn model\r\n",
        "\r\n",
        "\r\n",
        "K.clear_session()\r\n",
        "my_model = Net()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t9mIVMYquO9"
      },
      "source": [
        "# Copy the weight to empty model and strip the weight of each layer that directly connecting with the last Pooling layer by using pruning position list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJ0rtoSZ3aV"
      },
      "source": [
        "conv_3_weight = bd_net.get_layer('conv_3').get_weights()[0]\r\n",
        "conv_3_bias = bd_net.get_layer('conv_3').get_weights()[1]\r\n",
        "conv_4_weight = bd_net.get_layer('conv_4').get_weights()[0]\r\n",
        "conv_4_bias = bd_net.get_layer('conv_4').get_weights()[1]\r\n",
        "fc_1_weight = bd_net.get_layer('fc_1').get_weights()[0]\r\n",
        "fc_1_bias = bd_net.get_layer('fc_1').get_weights()[1]\r\n",
        "\r\n",
        "for layer in my_model.layers:\r\n",
        "  if layer.name == 'conv_3':\r\n",
        "    my_model.get_layer('conv_3').set_weights([conv_3_weight[:,:,:,pruning_position],conv_3_bias[pruning_position]])\r\n",
        "  elif layer.name == 'conv_4':\r\n",
        "    my_model.get_layer('conv_4').set_weights([conv_4_weight[:,:,pruning_position,:],conv_4_bias])\r\n",
        "  elif layer.name == 'fc_1':\r\n",
        "    my_model.get_layer('fc_1').set_weights([fc_1_weight.reshape(60,20,-1)[pruning_position,:,:].reshape((60-cut_num)*20,-1),fc_1_bias])\r\n",
        "  else:\r\n",
        "    my_model.get_layer(layer.name).set_weights(bd_net.get_layer(layer.name).get_weights())\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wne8g-tOrErY"
      },
      "source": [
        "# Fit new model with clean training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I99IAh6LkgNm",
        "outputId": "37d130c5-374e-4e40-f9da-c064c8d3fa1b"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "my_model.compile(optimizer='adam',\r\n",
        "              loss=loss_fn,\r\n",
        "              metrics=['accuracy'])\r\n",
        "my_model.fit(x_data, y_data, epochs=fit_epoch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "361/361 [==============================] - 59s 163ms/step - loss: 2.5589 - accuracy: 0.5190\n",
            "Epoch 2/10\n",
            "361/361 [==============================] - 59s 163ms/step - loss: 0.1912 - accuracy: 0.9544\n",
            "Epoch 3/10\n",
            "361/361 [==============================] - 59s 163ms/step - loss: 0.1345 - accuracy: 0.9588\n",
            "Epoch 4/10\n",
            "361/361 [==============================] - 59s 165ms/step - loss: 0.1274 - accuracy: 0.9659\n",
            "Epoch 5/10\n",
            "361/361 [==============================] - 58s 162ms/step - loss: 0.1296 - accuracy: 0.9640\n",
            "Epoch 6/10\n",
            "361/361 [==============================] - 59s 162ms/step - loss: 0.0725 - accuracy: 0.9794\n",
            "Epoch 7/10\n",
            "361/361 [==============================] - 59s 164ms/step - loss: 0.0877 - accuracy: 0.9780\n",
            "Epoch 8/10\n",
            "361/361 [==============================] - 60s 166ms/step - loss: 0.0859 - accuracy: 0.9740\n",
            "Epoch 9/10\n",
            "361/361 [==============================] - 61s 169ms/step - loss: 0.0610 - accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "361/361 [==============================] - 63s 173ms/step - loss: 0.0791 - accuracy: 0.9792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6275c9c518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxkZ1dqErQ4c"
      },
      "source": [
        "# New model performance on clean training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0fu1axJc41o",
        "outputId": "9aee6fab-c7d9-4908-c1f7-df1d62d55986"
      },
      "source": [
        "clean_label_p = np.argmax(my_model.predict(x_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_data))*100\r\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 96.9342686412055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDsqoDUG1iQY"
      },
      "source": [
        "# Save the model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUYQZIFi1iQY"
      },
      "source": [
        "my_model.save('anonymous_2_new_model.h5') "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uys5ON6a57Vh"
      },
      "source": [
        "# New model performance on clean testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RFQBnb24r9k",
        "outputId": "875dee4c-40ca-4fcd-ec97-963e793204cb"
      },
      "source": [
        "x_test_data, y_test_data = data_loader(test_data)\r\n",
        "x_test_data = data_process(x_test_data)\r\n",
        "model = load_model('/content/anonymous_2_new_model.h5')\r\n",
        "clean_label_p = np.argmax(model.predict(x_test_data), axis=1)\r\n",
        "class_accu = np.mean(np.equal(clean_label_p, y_test_data))*100\r\n",
        "print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy: 85.09742790335152\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}